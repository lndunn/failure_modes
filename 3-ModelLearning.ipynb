{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import json\n",
    "import datetime\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy import stats, special\n",
    "\n",
    "import utils\n",
    "import links\n",
    "import generators\n",
    "import estimation\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definitions of non-intuitive things\n",
    "\n",
    "#### What is X?\n",
    "X is a matrix of weather conditions generated in 1-InputGeneration.ipynb\n",
    "\n",
    "The data are synthetic, but they're based on statistical properties of real weather data.\n",
    "\n",
    "#### What is a scenario?\n",
    "Different \"scenarios\" represent different failure processes used to generate the data. These could be constant, piecewise linear, etc.\n",
    "\n",
    "Sceanrios are pre-defined in \"inputs/scenarios.csv\". Right now they're completely made up. Next steps are to use realistic assumptions about the lifetime and failure properties of grid assets (ultimately this piece goes in 2-ScenarioGeneration.ipynb - but for now that notebook is a mess and accomplishes nothing)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fleet_size=10000\n",
    "X = pd.read_csv('inputs/weather.csv', index_col='time')\n",
    "X.head()\n",
    "\n",
    "scenarios = pd.read_csv('inputs/scenarios.csv', index_col='name')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "191.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "        \n",
    "for i, scenario in scenarios.iterrows():\n",
    "    if i != 28:\n",
    "        continue\n",
    "    params = generators.params(scenario, fleet_size=fleet_size)\n",
    "    failures, failure_rate = generators.failure_data(params, X, links.Link, fleet_size=fleet_size)\n",
    "    if 'scenario%i'%(i) not in os.listdir('scenarios/'):\n",
    "        os.mkdir(os.path.join('scenarios', 'scenario%i'%(i)))\n",
    "        os.mkdir(os.path.join('scenarios', 'scenario%i'%(i), 'plots'))\n",
    "        \n",
    "    df = pd.DataFrame(index=failures.index)\n",
    "    df['count'] = failures\n",
    "    df['rate'] = failure_rate\n",
    "    \n",
    "    print failures.max()\n",
    "\n",
    "    df.to_csv(os.path.join('scenarios','scenario%i'%(i),'failures.csv'), header=True)\n",
    "    params.to_csv(os.path.join('scenarios','scenario%i'%(i),'parameters.csv'), header=True)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scenario analysis\n",
    "It takes quite a while to run through a scenario, let alone all of them. If you're just playing around, you can change \"scenarios_list\" to run only a subset of scenarios, or change \"mcmc_stopping_criteria\" to stop after fewer iterations. People will run ~1e5 or 1e6 iterations, but if the model is a good fit (big if, see 5.2) then it converges much faster.\n",
    "\n",
    "Just a heads up. :-)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 0 into shape (0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-152-04467b2804be>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m             \u001b[0mcov\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransition_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlinks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLink\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfleet_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchain_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m             \u001b[0mestimation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_chain_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcov\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscenario\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/laureldunn/Dropbox/Grid/pscc_paper/estimation.pyc\u001b[0m in \u001b[0;36mtransition_function\u001b[0;34m(X, y, link, fleet_size, target_acceptance, tol, chain_size)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maverage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mtarget_acceptance\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mtol\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m         \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetropolis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlink\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfleet_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcov\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcov\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mit\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mit\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0mchain_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m         \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/laureldunn/Dropbox/Grid/pscc_paper/estimation.pyc\u001b[0m in \u001b[0;36mmetropolis\u001b[0;34m(p0, x, y, link, fleet_size, cov, jump, accept_reject, stop)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjump\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m             dp = pd.Series(stats.multivariate_normal.rvs(mean=np.zeros((len(cov),)), cov=cov),\n\u001b[0m\u001b[1;32m     44\u001b[0m                           index=parameters.keys())\n\u001b[1;32m     45\u001b[0m             \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/laureldunn/anaconda2/lib/python2.7/site-packages/scipy/stats/_multivariate.pyc\u001b[0m in \u001b[0;36mrvs\u001b[0;34m(self, mean, cov, size, random_state)\u001b[0m\n\u001b[1;32m    658\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    659\u001b[0m         \u001b[0mrandom_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_random_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 660\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultivariate_normal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcov\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    661\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_squeeze_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    662\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mmtrand.pyx\u001b[0m in \u001b[0;36mmtrand.RandomState.multivariate_normal\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 0 into shape (0)"
     ]
    }
   ],
   "source": [
    "\n",
    "# USE RANDOM WALK\n",
    "mcmc_random_walk = lambda theta, cov: pd.Series(stats.multivariate_normal.rvs(mean=theta, cov=cov),\n",
    "                                           index=theta.index)\n",
    "\n",
    "scenarios = pd.read_csv('inputs/scenarios.csv', index_col='name')\n",
    "\n",
    "fleet_size = 10000\n",
    "scenarios_list = scenarios.index\n",
    "mcmc_stopping_criteria = lambda it: it<5e4\n",
    "\n",
    "for i in scenarios_list:\n",
    "    if i != 19:\n",
    "        continue\n",
    "    scenario = 'scenario%i'%(i)\n",
    "\n",
    "    y = pd.read_csv(os.path.join('scenarios', scenario, 'failures.csv'), index_col='time')['count']\n",
    "    \n",
    "    if y.sum() == 0:\n",
    "        continue\n",
    "\n",
    "#     x_vars = [['Wind',],['Wind','Precip',],['Wind','Precip','WindStorm'],]\n",
    "    x_vars = [['Wind',],['Wind','DayPrecip',],['Wind','DayPrecip','WindStorm'],]\n",
    "    for var in x_vars:\n",
    "        model_name = '+'.join(var)\n",
    "        \n",
    "        if os.path.exists(os.path.join('scenarios', scenario, 'chains', '%s.csv'%(model_name))):\n",
    "            continue\n",
    "            \n",
    "        _X = X[var]\n",
    "\n",
    "        # -------------------------------\n",
    "        # TUNING MCMC SAMPLER\n",
    "        # Transition in the MCMC chain is a random walk where step size is gaussian and spherical\n",
    "        # If the step size is too big, parameter updates are rarely accepted (poor mixing)\n",
    "        # If the step size is too small, autocorrelation is high, convergence is slow\n",
    "        # in both cases the chain needs to be longer.\n",
    "        # Rule of thumb is to choose sigma so that acceptance rate is 25%\n",
    "        \n",
    "        \n",
    "#         cov, p0 = estimation.transition_function(_X, y, links.Link(), fleet_size, tol=0.01, chain_size=1000)\n",
    "#         estimation.save_chain_params(cov, p0, scenario, model_name)\n",
    "        \n",
    "#         out = estimation.get_existing_transition_params(scenario, model_name)\n",
    "        out = []\n",
    "        if len(out) == 0:\n",
    "            cov, p0 = estimation.transition_function(_X, y, links.Link(), fleet_size, tol=0.01, chain_size=1000)\n",
    "            estimation.save_chain_params(cov, p0, scenario, model_name)\n",
    "        else:\n",
    "            cov, p0 = out\n",
    "            \n",
    "        params, acceptance = estimation.metropolis(p0, _X, y, links.Link(), fleet_size, \n",
    "                                                   jump=mcmc_random_walk, accept_reject=True, \n",
    "                                                   cov=cov, stop=mcmc_stopping_criteria)\n",
    "        params['acceptance'] = acceptance\n",
    "\n",
    "        if not os.path.exists(os.path.join('scenarios', scenario, 'chains')):\n",
    "            os.mkdir(os.path.join('scenarios', scenario, 'chains'))\n",
    "\n",
    "        params.to_csv(os.path.join('scenarios', scenario, 'chains', '%s.csv'%(model_name)))\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14673.0"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'scenario27'"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scenario\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'theta_star' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-64-e9beaf4f6c77>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcov\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtheta_star\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'theta_star' is not defined"
     ]
    }
   ],
   "source": [
    "cov, theta_star"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "slope.Precip       -10.070734\n",
       "slope.Wind           0.340613\n",
       "threshold.Precip     0.000000\n",
       "threshold.Wind      46.502160\n",
       "dtype: float64"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
