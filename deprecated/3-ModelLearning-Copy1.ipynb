{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import json\n",
    "import datetime\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy import stats, special\n",
    "\n",
    "import utils\n",
    "import links\n",
    "import generators\n",
    "import estimation\n",
    "\n",
    "from sklearn import mixture\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definitions of non-intuitive things\n",
    "\n",
    "#### What is X?\n",
    "X is a matrix of weather conditions generated in 1-InputGeneration.ipynb\n",
    "\n",
    "The data are synthetic, but they're based on statistical properties of real weather data.\n",
    "\n",
    "#### What is a scenario?\n",
    "Different \"scenarios\" represent different failure processes used to generate the data. These could be constant, piecewise linear, etc.\n",
    "\n",
    "Sceanrios are pre-defined in \"inputs/scenarios.csv\". Right now they're completely made up. Next steps are to use realistic assumptions about the lifetime and failure properties of grid assets (ultimately this piece goes in 2-ScenarioGeneration.ipynb - but for now that notebook is a mess and accomplishes nothing)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Precip</th>\n",
       "      <th>Temp</th>\n",
       "      <th>Wind</th>\n",
       "      <th>DayPrecip</th>\n",
       "      <th>HotCalm</th>\n",
       "      <th>WindStorm</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>54.50</td>\n",
       "      <td>5.67</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.611993</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>53.46</td>\n",
       "      <td>3.85</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.885714</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>53.16</td>\n",
       "      <td>3.34</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.916168</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>52.57</td>\n",
       "      <td>3.62</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.522099</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>51.00</td>\n",
       "      <td>3.77</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.527851</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Precip   Temp  Wind  DayPrecip    HotCalm  WindStorm\n",
       "time                                                      \n",
       "0        0.0  54.50  5.67        0.0   9.611993        0.0\n",
       "1        0.0  53.46  3.85        0.0  13.885714        0.0\n",
       "2        0.0  53.16  3.34        0.0  15.916168        0.0\n",
       "3        0.0  52.57  3.62        0.0  14.522099        0.0\n",
       "4        0.0  51.00  3.77        0.0  13.527851        0.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fleet_size=10000\n",
    "X = pd.read_csv('inputs/weather.csv', index_col='time')\n",
    "X.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71.0\n"
     ]
    }
   ],
   "source": [
    "scenarios = pd.read_csv('inputs/scenarios.csv', index_col='name')\n",
    "        \n",
    "for i, scenario in scenarios.iterrows():\n",
    "    if i != 24:\n",
    "        continue\n",
    "    params = generators.params(scenario, fleet_size=fleet_size)\n",
    "    failures, failure_rate = generators.failure_data(params, X, links.Link, fleet_size=fleet_size)\n",
    "    if 'scenario%i'%(i) not in os.listdir('scenarios/'):\n",
    "        os.mkdir(os.path.join('scenarios', 'scenario%i'%(i)))\n",
    "        os.mkdir(os.path.join('scenarios', 'scenario%i'%(i), 'plots'))\n",
    "        \n",
    "    df = pd.DataFrame(index=failures.index)\n",
    "    df['count'] = failures\n",
    "    df['rate'] = failure_rate\n",
    "    \n",
    "    print df['count'].max()\n",
    "\n",
    "    df.to_csv(os.path.join('scenarios','scenario%i'%(i),'failures.csv'), header=True)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scenario analysis\n",
    "It takes quite a while to run through a scenario, let alone all of them. If you're just playing around, you can change \"scenarios_list\" to run only a subset of scenarios, or change \"mcmc_stopping_criteria\" to stop after fewer iterations. People will run ~1e5 or 1e6 iterations, but if the model is a good fit (big if, see 5.2) then it converges much faster.\n",
    "\n",
    "Just a heads up. :-)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scenario19\n",
      "191.0\n",
      "     slope.Precip  slope.Wind  threshold.Precip  threshold.Wind\n",
      "0        9.603816    0.004659            0.0686              71\n",
      "1        1.052009    0.013105            0.0686              71\n",
      "2        0.496135    0.014990            0.0686              71\n",
      "3        1.105126    0.012515            0.0686              71\n",
      "4        0.588370    0.013959            0.0686              71\n",
      "5        0.803289    0.013520            0.0686              71\n",
      "6        0.000018    0.013718            0.0686              71\n",
      "7        0.000019    0.014456            0.0686              71\n",
      "8        0.491127    0.013085            0.0686              71\n",
      "9        1.166816    0.013022            0.0686              71\n",
      "10       1.304862    0.013973            0.0686              71\n",
      "11       0.865780    0.012464            0.0686              71\n",
      "12       0.931625    0.013366            0.0686              71\n",
      "13       0.000019    0.014531            0.0686              71\n",
      "14       0.359314    0.013549            0.0686              71\n",
      "15       0.000017    0.013731            0.0686              71\n",
      "16       0.000018    0.014506            0.0686              71\n",
      "17       0.697027    0.014308            0.0686              71\n",
      "18       0.275061    0.014624            0.0686              71\n",
      "19       0.000019    0.014034            0.0686              71\n",
      "20       0.481179    0.014984            0.0686              71\n",
      "21       1.032587    0.013776            0.0686              71\n",
      "22       0.895894    0.013511            0.0686              71\n",
      "23       0.677230    0.013829            0.0686              71\n",
      "24       0.000018    0.014609            0.0686              71\n",
      "25       0.691097    0.013790            0.0686              71\n",
      "26       0.872097    0.013706            0.0686              71\n",
      "27       1.244268    0.012332            0.0686              71\n",
      "28       0.931427    0.014426            0.0686              71\n",
      "29       0.729626    0.014377            0.0686              71\n",
      "..            ...         ...               ...             ...\n",
      "71       0.000017    0.014336            0.0686              71\n",
      "72       0.551774    0.012811            0.0686              71\n",
      "73       0.258853    0.014673            0.0686              71\n",
      "74       0.721901    0.014602            0.0686              71\n",
      "75       0.751707    0.013408            0.0686              71\n",
      "76       0.661553    0.012922            0.0686              71\n",
      "77       0.896375    0.014121            0.0686              71\n",
      "78       0.000016    0.013661            0.0686              71\n",
      "79       0.573962    0.013275            0.0686              71\n",
      "80       0.000019    0.015469            0.0686              71\n",
      "81       0.462003    0.013735            0.0686              71\n",
      "82       0.311761    0.014514            0.0686              71\n",
      "83       0.000015    0.013274            0.0686              71\n",
      "84       0.634475    0.014087            0.0686              71\n",
      "85       0.941754    0.014179            0.0686              71\n",
      "86       0.666361    0.013539            0.0686              71\n",
      "87       0.485747    0.013552            0.0686              71\n",
      "88       0.527852    0.014024            0.0686              71\n",
      "89       0.000018    0.013718            0.0686              71\n",
      "90       0.350339    0.014757            0.0686              71\n",
      "91       1.080273    0.013293            0.0686              71\n",
      "92       1.036759    0.011940            0.0686              71\n",
      "93       0.668669    0.014176            0.0686              71\n",
      "94       0.657154    0.014130            0.0686              71\n",
      "95       1.042262    0.014167            0.0686              71\n",
      "96       0.888219    0.012758            0.0686              71\n",
      "97       0.622108    0.013026            0.0686              71\n",
      "98       0.434809    0.012736            0.0686              71\n",
      "99       1.038911    0.013438            0.0686              71\n",
      "100      1.187818    0.013827            0.0686              71\n",
      "\n",
      "[101 rows x 4 columns]\n",
      "-inf -inf [10.534735883619343, 0.0036938129752946626, 0.0686, 71.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "estimation.py:54: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  \n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "probabilities contain NaN",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-6ed8990d4798>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;31m#         out = []\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m             \u001b[0mcov\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransition_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlinks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLink\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfleet_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchain_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m             \u001b[0mestimation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_chain_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcov\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscenario\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/laureldunn/Dropbox/Grid/pscc_paper/estimation.py\u001b[0m in \u001b[0;36mtransition_function\u001b[0;34m(X, y, link, fleet_size, target_acceptance, tol, chain_size)\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maverage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mtarget_acceptance\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mtol\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m         \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetropolis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlink\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfleet_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcov\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcov\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mit\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mit\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0mchain_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m         \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/laureldunn/Dropbox/Grid/pscc_paper/estimation.py\u001b[0m in \u001b[0;36mmetropolis\u001b[0;34m(p0, x, y, link, fleet_size, cov, jump, accept_reject, stop)\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0maccept_reject\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0malpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mL\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlikelihood\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m             \u001b[0maccept\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0maccept\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mmtrand.pyx\u001b[0m in \u001b[0;36mmtrand.RandomState.choice\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: probabilities contain NaN"
     ]
    }
   ],
   "source": [
    "\n",
    "# USE RANDOM WALK\n",
    "mcmc_random_walk = lambda theta, cov: pd.Series(stats.multivariate_normal.rvs(mean=theta, cov=cov),\n",
    "                                           index=theta.index)\n",
    "\n",
    "def hybrid_gibbs_sampler(theta, cov, design_lims=[40,50]):\n",
    "    theta_star = pd.Series(index=theta.index)\n",
    "    theta_star.loc['threshold.Wind'] = stats.uniform.rvs(*design_lims)\n",
    "    for param in ['threshold.Precip','threshold.WindStorm']:\n",
    "        if param in theta_star.index:\n",
    "            key = param.split('.')[1]\n",
    "            idx = X[key] > 0\n",
    "            theta_star.loc[param] = stats.uniform.rvs(X[key][idx].min(), X[key][idx].max())\n",
    "\n",
    "    for _var in var:\n",
    "        A = 'slope.%s'%(_var)\n",
    "        B = 'threshold.%s'%(_var)\n",
    "        cov_inv = pd.DataFrame(np.linalg.inv(cov), columns=cov.keys(), index=cov.index)\n",
    "\n",
    "        conditional_mean = theta.loc[A] + cov[A].loc[B]*cov_inv[B].loc[B]*(theta_star.loc[B] - theta.loc[B])\n",
    "        conditional_var = cov[A].loc[A] - cov[A].loc[B]*cov_inv[B].loc[B]*cov[B].loc[A]\n",
    "\n",
    "        theta_star.loc[A] = stats.norm.rvs(conditional_mean, np.sqrt(conditional_var))\n",
    "    return theta_star\n",
    "\n",
    "scenarios = pd.read_csv('inputs/scenarios.csv', index_col='name')\n",
    "\n",
    "fleet_size = 10000\n",
    "scenarios_list = scenarios.index\n",
    "mcmc_stopping_criteria = lambda it: it<5e4\n",
    "\n",
    "for i in scenarios_list:\n",
    "    if i < 19:\n",
    "        continue\n",
    "    scenario = 'scenario%i'%(i)\n",
    "    print scenario\n",
    "\n",
    "    y = pd.read_csv(os.path.join('scenarios', scenario, 'failures.csv'), index_col='time')['count']\n",
    "    \n",
    "    print y.max()\n",
    "\n",
    "    x_vars = [['Wind',],['Wind','Precip',],['Wind','Precip','WindStorm'],]\n",
    "    for var in x_vars[1:]:\n",
    "        model_name = '+'.join(var)\n",
    "        \n",
    "#         if os.path.exists(os.path.join('scenarios', scenario, 'chains', '%s.csv'%(model_name))):\n",
    "#             continue\n",
    "            \n",
    "        _X = X[var]\n",
    "\n",
    "        # -------------------------------\n",
    "        # TUNING MCMC SAMPLER\n",
    "        # Transition in the MCMC chain is a random walk where step size is gaussian and spherical\n",
    "        # If the step size is too big, parameter updates are rarely accepted (poor mixing)\n",
    "        # If the step size is too small, autocorrelation is high, convergence is slow\n",
    "        # in both cases the chain needs to be longer.\n",
    "        # Rule of thumb is to choose sigma so that acceptance rate is 25%\n",
    "        \n",
    "        \n",
    "#         cov, p0 = estimation.transition_function(_X, y, links.Link(), fleet_size, tol=0.01, chain_size=1000)\n",
    "#         estimation.save_chain_params(cov, p0, scenario, model_name)\n",
    "        \n",
    "        out = estimation.get_existing_transition_params(scenario, model_name)\n",
    "#         out = []\n",
    "        if len(out) == 0:\n",
    "            cov, p0 = estimation.transition_function(_X, y, links.Link(), fleet_size, tol=0.01, chain_size=1000)\n",
    "            estimation.save_chain_params(cov, p0, scenario, model_name)\n",
    "        else:\n",
    "            cov, p0 = out\n",
    "\n",
    "#         p0, cov = links.Link().init_params(_X, y, fleet_size)\n",
    "#         p0 = pd.io.json.json_normalize(p0)\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "                        \n",
    "\n",
    "        params, acceptance = estimation.metropolis(p0, _X, y, links.Link(), fleet_size, \n",
    "                                                   jump=mcmc_random_walk, accept_reject=True, \n",
    "                                                   cov=cov, stop=mcmc_stopping_criteria)\n",
    "        params['acceptance'] = acceptance\n",
    "\n",
    "        if not os.path.exists(os.path.join('scenarios', scenario, 'chains')):\n",
    "            os.mkdir(os.path.join('scenarios', scenario, 'chains'))\n",
    "\n",
    "        params.to_csv(os.path.join('scenarios', scenario, 'chains', '%s.csv'%(model_name)))\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "21000\n",
      "22000\n",
      "23000\n",
      "24000\n",
      "25000\n",
      "26000\n",
      "27000\n",
      "28000\n",
      "29000\n",
      "30000\n",
      "31000\n",
      "32000\n",
      "33000\n",
      "34000\n",
      "35000\n",
      "36000\n",
      "37000\n",
      "38000\n",
      "39000\n",
      "40000\n",
      "41000\n",
      "42000\n",
      "43000\n",
      "44000\n",
      "45000\n",
      "46000\n",
      "47000\n",
      "48000\n",
      "49000\n",
      "50000\n",
      "51000\n",
      "52000\n",
      "53000\n",
      "54000\n",
      "55000\n",
      "56000\n",
      "57000\n",
      "58000\n",
      "59000\n",
      "60000\n",
      "61000\n",
      "62000\n",
      "63000\n",
      "64000\n",
      "65000\n",
      "66000\n",
      "67000\n",
      "68000\n",
      "69000\n",
      "70000\n",
      "71000\n",
      "72000\n",
      "73000\n",
      "74000\n",
      "75000\n",
      "76000\n",
      "77000\n",
      "78000\n",
      "79000\n",
      "80000\n",
      "81000\n",
      "82000\n",
      "83000\n",
      "84000\n",
      "85000\n",
      "86000\n",
      "87000\n",
      "88000\n",
      "89000\n",
      "90000\n",
      "91000\n",
      "92000\n",
      "93000\n",
      "94000\n",
      "95000\n",
      "96000\n",
      "97000\n",
      "98000\n",
      "99000\n",
      "100000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "21000\n",
      "22000\n",
      "23000\n",
      "24000\n",
      "25000\n",
      "26000\n",
      "27000\n",
      "28000\n",
      "29000\n",
      "30000\n",
      "31000\n",
      "32000\n",
      "33000\n",
      "34000\n",
      "35000\n",
      "36000\n",
      "37000\n",
      "38000\n",
      "39000\n",
      "40000\n",
      "41000\n",
      "42000\n",
      "43000\n",
      "44000\n",
      "45000\n",
      "46000\n",
      "47000\n",
      "48000\n",
      "49000\n",
      "50000\n",
      "51000\n",
      "52000\n",
      "53000\n",
      "54000\n",
      "55000\n",
      "56000\n",
      "57000\n",
      "58000\n",
      "59000\n",
      "60000\n",
      "61000\n",
      "62000\n",
      "63000\n",
      "64000\n",
      "65000\n",
      "66000\n",
      "67000\n",
      "68000\n",
      "69000\n",
      "70000\n",
      "71000\n",
      "72000\n",
      "73000\n",
      "74000\n",
      "75000\n",
      "76000\n",
      "77000\n",
      "78000\n",
      "79000\n",
      "80000\n",
      "81000\n",
      "82000\n",
      "83000\n",
      "84000\n",
      "85000\n",
      "86000\n",
      "87000\n",
      "88000\n",
      "89000\n",
      "90000\n",
      "91000\n",
      "92000\n",
      "93000\n",
      "94000\n",
      "95000\n",
      "96000\n",
      "97000\n",
      "98000\n",
      "99000\n",
      "100000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# USE RANDOM WALK\n",
    "mcmc_random_walk = lambda theta, cov: pd.Series(stats.multivariate_normal.rvs(mean=theta, cov=cov),\n",
    "                                           index=theta.index)\n",
    "\n",
    "def hybrid_gibbs_sampler(theta, cov, design_lims=[40,50]):\n",
    "    theta_star = pd.Series(index=theta.index)\n",
    "    theta_star.loc['threshold.Wind'] = stats.uniform.rvs(*design_lims)\n",
    "    for param in ['threshold.Precip','threshold.WindStorm']:\n",
    "        if param in theta_star.index:\n",
    "            key = param.split('.')[1]\n",
    "            idx = X[key] > 0\n",
    "            theta_star.loc[param] = stats.uniform.rvs(X[key][idx].min(), X[key][idx].max())\n",
    "\n",
    "    for _var in var:\n",
    "        A = 'slope.%s'%(_var)\n",
    "        B = 'threshold.%s'%(_var)\n",
    "        cov_inv = pd.DataFrame(np.linalg.inv(cov), columns=cov.keys(), index=cov.index)\n",
    "\n",
    "        conditional_mean = theta.loc[A] + cov[A].loc[B]*cov_inv[B].loc[B]*(theta_star.loc[B] - theta.loc[B])\n",
    "        conditional_var = cov[A].loc[A] - cov[A].loc[B]*cov_inv[B].loc[B]*cov[B].loc[A]\n",
    "\n",
    "        theta_star.loc[A] = stats.norm.rvs(conditional_mean, np.sqrt(conditional_var))\n",
    "    return theta_star\n",
    "\n",
    "scenarios = pd.read_csv('inputs/scenarios.csv', index_col='name')\n",
    "\n",
    "fleet_size = 10000\n",
    "scenarios_list = scenarios.index\n",
    "mcmc_stopping_criteria = lambda it: it<1e5\n",
    "extend=False\n",
    "\n",
    "for i in scenarios_list:\n",
    "    if i < 19:\n",
    "        continue\n",
    "    scenario = 'scenario%i'%(i)\n",
    "\n",
    "    y = pd.read_csv(os.path.join('scenarios', scenario, 'failures.csv'), index_col='time')['count']\n",
    "    \n",
    "    if y.sum() == 0:\n",
    "        continue\n",
    "\n",
    "#     x_vars = [['Wind',],['Wind','Precip',],['Wind','Precip','WindStorm'],]\n",
    "    x_vars = [['Wind','DayPrecip',],['Wind','DayPrecip','WindStorm'],]\n",
    "    for var in x_vars:\n",
    "        model_name = '+'.join(var)\n",
    "        \n",
    "#         if os.path.exists(os.path.join('scenarios', scenario, 'chains', '%s.csv'%(model_name))):\n",
    "#             continue\n",
    "            \n",
    "        _X = X[var]\n",
    "\n",
    "        # -------------------------------\n",
    "        # TUNING MCMC SAMPLER\n",
    "        # Transition in the MCMC chain is a random walk where step size is gaussian and spherical\n",
    "        # If the step size is too big, parameter updates are rarely accepted (poor mixing)\n",
    "        # If the step size is too small, autocorrelation is high, convergence is slow\n",
    "        # in both cases the chain needs to be longer.\n",
    "        # Rule of thumb is to choose sigma so that acceptance rate is 25%\n",
    "        \n",
    "        \n",
    "#         cov, p0 = estimation.transition_function(_X, y, links.Link(), fleet_size, tol=0.01, chain_size=1000)\n",
    "#         estimation.save_chain_params(cov, p0, scenario, model_name)\n",
    "        \n",
    "#         out = estimation.get_existing_transition_params(scenario, model_name)\n",
    "        out = []\n",
    "        if len(out) == 0:\n",
    "            try:\n",
    "                cov, p0 = estimation.transition_function(_X, y, links.Link(), fleet_size, tol=0.01, chain_size=1000)\n",
    "            except ValueError:\n",
    "                continue\n",
    "            estimation.save_chain_params(cov, p0, scenario, model_name)\n",
    "        else:\n",
    "            cov, p0 = out\n",
    "            if extend == True:\n",
    "                p0 = pd.read_csv(os.path.join('scenarios', scenario, 'chains', '%s.csv'%(model_name)), \n",
    "                                 usecols=p0.index).iloc[-1]\n",
    "            print p0\n",
    "        params, acceptance = estimation.metropolis(p0, _X, y, links.Link(), fleet_size, \n",
    "                                                   jump=mcmc_random_walk, accept_reject=True, \n",
    "                                                   cov=cov, stop=mcmc_stopping_criteria)\n",
    "        params['acceptance'] = acceptance\n",
    "\n",
    "        if not os.path.exists(os.path.join('scenarios', scenario, 'chains')):\n",
    "            os.mkdir(os.path.join('scenarios', scenario, 'chains'))\n",
    "\n",
    "        if extend:\n",
    "            df = pd.read_csv(os.path.join('scenarios', scenario, 'chains', '%s.csv'%(model_name)), index_col=0)\n",
    "            df = df.append(params, ignore_index=True)\n",
    "            df.to_csv(os.path.join('scenarios', scenario, 'chains', '%s.csv'%(model_name)))\n",
    "\n",
    "        else:\n",
    "            params.to_csv(os.path.join('scenarios', scenario, 'chains', '%s.csv'%(model_name)))\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'theta_star' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-64-e9beaf4f6c77>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcov\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtheta_star\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'theta_star' is not defined"
     ]
    }
   ],
   "source": [
    "cov, theta_star"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "slope.Precip       -10.070734\n",
       "slope.Wind           0.340613\n",
       "threshold.Precip     0.000000\n",
       "threshold.Wind      46.502160\n",
       "dtype: float64"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
